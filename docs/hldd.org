#+TITLE: Spread: High-Level Technical Design
#+AUTHOR: F. Bielejec
#+EMAIL: fbielejec@gmail.com
#+TEXINFO_PRINTED_TITLE: Spread: High-Level Technical Design
#+SUBTITLE: version {{{version}}}, {{{updated}}}
#+OPTIONS: ':t toc:t author:t email:t
#+LANGUAGE: en
#+STARTUP: overview

* TODO Introduction
* DONE Current System
# Instructions: If applicable, this section describes the current system that is being replaced, enhanced, or upgraded.
Most recent version of Spread in use today is a classic desktop application, packaged and distributed as an executable Java JAR.
The home tab of the user interface allows for parsing 4 distinct types of input.

#+CAPTION: Tab for parsing discrete traits tree
file:current_system1.png

A detailed tutorial, along with more screenshots is hosted [[https://rega.kuleuven.be/cev/ecv/software/SpreaD3_tutorial][here]].

** DONE Functional Description
[[https://rega.kuleuven.be/cev/ecv/software/SpreaD3][SpreaD3]] is an application to analyze and visualize pathogen phylodynamic reconstructions resulting from Bayesian inference of sequence and trait evolutionary processes.

As such it places itself at the end of a file-mediated pipeline and is geared towards analyzing and displaying the outputs of analysis from a popular Bayesian phylogenetic inference software [[https://github.com/beast-dev/beast-mcmc][BEAST]].
An overview and documentation of the the BEAST software package can be found [[http://beast.community/index.html][here]].

# In theory it can also accommodate input generated by other phylogenetic inference tools, as long as the nodes and branches of the trees are annotated using the compatible syntax.

Below diagram presents a general context in which SpreaD3 operates:

#+begin_src plantuml :file functional.png
package "BEAST inputs" {
  file "Genetic data" as genetic
  file "Temporal data" as temporal
  file "Other metadata" as meta
}

package "SPREAD inputs" {
  file "MCC tree with discrete traits" as discreteTree
  file "MCC tree with continuous traits" as continuousTree
  file "tree distribution with continuous traits" as continuousTrees
  file "log file from BSSVS analysis" as bssvs
}

genetic -down-> [BEAST]
temporal -down-> [BEAST]
meta -down-> [BEAST]

[BEAST] -down-> discreteTree
[BEAST] -down-> continuousTree
[BEAST] -down-> continuousTrees
[BEAST] -down-> bssvs

discreteTree -down-> [SPREAD] : geographical coordinates
continuousTree -down-> [SPREAD]
continuousTrees -down-> [SPREAD]
bssvs -down-> [SPREAD]

[SPREAD] ..> Visualisation : geojson map data

#+end_src
#+RESULTS:
[[file:functional.png]]

When analyzing trees annotated with the discrete data Spread needs additional inputs in the form of delimited text-files matching discrete traits with the geographical coordinates, typicaly it also needs user-supplied map data in the form of [[https://geojson.org/][geoJSON]] files.

The final visualisation comes in a form of an interactive map, with the data overlayed on top of it, where the user has control over various aspects of color coding, the attributes associated with each map component and color choices.

** DONE User Community Description
Primary users of the Spread software are researchers in the fields of epidemiology, virology, phylogenetics and bioinformatics.
The visualisations stemming frm SPREAD can be used to inform medical workers, health care officials, decision-makers etc.
** DONE Technical Architecture <<previous_tech_arch>>
In this section we identify and describe the architecture of the current system.

# What type of processing is the current system responsible for?
Spreads main responsibility is parsing and processing of BEAST output files:
- Summary tree files with discrete or continuously annotated nodes
- Files with distribution of trees with continuous trait annotations
- Log files containing a posterior distribution of rate indicators from a Bayesian stochastic search variable selection procedure.

The information found in those files, combined with a geographical coordinates data (in the case of discretely annotated trees) is used to parse and represent the hierarchical tree structures as primitives (such as points or lines) on a map.
These primitives will typically have associated geographical (latitide / longitude coordinates), temporal (timestamps) and various other meta-data associated with them.
An exmaple of such a data-set (an MCC tree file with continuous annotations) can be found file:236_subG_PT_cauchy_geo.mcc.tre.

Parsing step produces a JSON file with a following schema:

#+begin_src plantuml :file json_schema.png
class "root" as root {
    .. Objects ..
    properties: [object Object]
}
class "properties" as root.properties {
    .. Objects ..
    timeLine: [object Object]
    axis:  [object Object]
    lineAttributes: [array [object Object]]
    pointAttributes: [array [object Object]]
    areaAttributes: [array [object Object]]
    layers: [array [object Object]]
}
class "timeLine" as root.properties.timeLine {
    .. Properties ..
    startTime: date
    endTime: date
}
class "axis" as root.properties.axis {
    .. Properties ..
    xCoordinate: string
    yCoordinate: string
}
class "line / point / area attributes" as root.properties.lineAttributes {
    .. Properties ..
    type: array
    .. Objects ..
    attribute: [object Object]
}

note left of root.properties.lineAttributes.attribute : Discrete attributes have a domain field listing all unique values \n Continuous have a range [min, max].

class "attribute" as root.properties.lineAttributes.attribute {
    .. Properties ..
    id: string
    scale: enum
    range : array[2]
    domain: array[n]
}

class "layers" as root.properties.layers {
    .. Properties ..
    type: array
    .. Objects ..
    geoJSONLayer: [object Object]
    treeLayer: [object Object]
}

class "tree" as root.properties.layers.tree {
    .. Properties ..
    id: string
    type: string
    description: string
    points: [array [object Object]]
    lines: [array [object Object]]
    areas: [array [object Object]]
}

class "points" as root.properties.layers.tree.points {
    .. Properties ..
    type: array
    .. Objects ..
    point: [object Object]
}

class "point" as root.properties.layers.tree.points.point {
    .. Properties ..
    id: number
    coordinate: [object Object]
    startTime: date
    attributes: [object Object]
}

class "lines" as root.properties.layers.tree.lines {
    .. Properties ..
    type: array
    .. Objects ..
    line: [object Object]
}

class "line" as root.properties.layers.tree.lines.line {
    .. Properties ..
    id: number
    startPointId: number
    endPointId:	number
    startTime: date
    endTime: date
    attributes: [object Object]
}

root -- root.properties
root.properties -- root.properties.timeLine
root.properties -- root.properties.axis
root.properties -- root.properties.lineAttributes
root.properties.lineAttributes -- root.properties.lineAttributes.attribute
root.properties -- root.properties.layers
root.properties.layers -- root.properties.layers.tree

root.properties.layers.tree -- root.properties.layers.tree.points
root.properties.layers.tree.points -- root.properties.layers.tree.points.point

root.properties.layers.tree -- root.properties.layers.tree.lines
root.properties.layers.tree.lines -- root.properties.layers.tree.lines.line

root.properties.layers.tree.points.point <|- root.properties.layers.tree.lines.line : two pointers

root.properties.lineAttributes.attribute <|- root.properties.layers.tree.points.point
root.properties.layers.tree.lines.line -|> root.properties.lineAttributes.attribute
#+end_src
#+RESULTS:
[[file:json_schema.png]]

An example of output generated from the program can be found here file:spread_data_example.json (it does not include the geoJSON layer which creates the map on which the estimates are displayed).
A minimal subset of this data : file:spread_data_example_minimal.json .
This subset contains a single branch joining two nodes and their corresponding meta-data (attributes).


Such JSON file is than loaded into the program once again to produce a visualisation:

#+begin_src plantuml :file subsystems.png
state Input {
  Discrete : summary tree file
  Discrete : BSSVS log file

  Discrete --> GeographicalCoordinates : combine
  GeographicalCoordinates : file with a mapping from trait name to its geographical coordinates

  Continuous : summary tree file
  Continuous : trees distribution file
}

Input --> JSON : parse data
JSON : file with geoJSON layer and data primitives for plotting

JSON --> VisualisationEngine : load file
VisualisationEngine : uses D3 libraries for plotting parsed data
#+end_src
#+RESULTS:
[[file:subsystems.png]]

The visualization is a stand-alone HTML document which user opens in the browser, gaining interactive control over different visualization components.
It can be controlled by a time slider, and tree projections over time can be animated, paused, fast-forwarded, or re-winded.
Color settings can be based on the attributes associated with each component and filled using selected color-palettes

# What are the major application components?
We can divide the application into three major components:
- parsing engine, capable of summarizing various inputs and combining them with external information, vanilla Java codebase.
- graphical user interface, written in the Swing framework.
- JavaScript visualization engine, which uses D3 library for rendering and creates a html + JS output in a user-specified location.

Spread is a desktop application, relying on end-user operating system for data storage, thread management etc.
The parsing engine and the graphical user-interface are both written in Java, with the visualization engine using a set of JavaScript libraries to create essentially a static web page which can be (locally) opened in the users browser.

* DONE Goals, Objectives, and Rationale for New or Significantly Modified System <<rationale>>

The most-recent version Spread (SemVer 0.9.7) was released in year 2016.
Since than it has attracted many users, and although individual downloads were not tracked, the joint number of citations with an earlier version of the software package is well over 600.
This highlights a need for user-friendly tool for visual display of pathogen dispersal.

At the same time not only is it a significant time-span for any software system to go without major maintenance, but a majority of the design and architecture was simply carried from the earlier version.
Below we higlight major shortcoming and ills plaguing the current version of Spread.

=desktop application=
All previous versions of Spread were a classic GUI desktop applications, installed on a personal or work computers.
They relied on the user Operating System to store, retrieve and analyze data.
Major shortcoming was the inability to easily retrieve and edit previous analyses, especially between different workstations.

It also hindered the development, as the major prevalent Jave Runtime Environment (JRE) installed across desktop computers at that time was version 6, making it impossible to use modern features of the programming language.
With a new 6 monthly [[https://www.oracle.com/java/technologies/java-se-support-roadmap.html][release cycle]] introduced recently by Oracle, it would be all the harder to push the burden of updating the JRE to the end-user.
In our opinion this necessitates a move to a classic server / client architecture, where the developers control the updates, Runtime Environment, data storage and other aspects of the development, in a manner that is transparent to the user, yet lifts all these usability constraints.

=data persistance=
This point ties to the previous one, yet due to it's importance it is discussed separately.
As already mentioned desktop version of Spread relied solely on the end user to store the inputs, outputs and results of the analysis.
It made it also her responsibility to move the data between different workstation, and maintain the file structure to be revisited should he want to re-analyse the data.
All of these concerns can be moved to the software itself with a use of Relational Database for storage.

In the previous software versions the generated visualisations came in a form of a static website created in a singel directory on the end-users computer.
The rendering step would simply bundle together the generated JSON data, the bundled JavaScript D3 [[https://github.com/phylogeography/d3-renderer][plotting scripts]] and the HTML entry-point.
It made it user responsibility to create and host this website or view it locally, by opening the index page in the browser.
In recent years many browsers stopped supporting accessing local data files, for security reasons. and users had to resort to using cumbersome command-line arguments to turn browsers unsafe features on.
By creating a classic client-server architecture we can use object-based storage architectures such as [[https://aws.amazon.com/s3/][Amazon S3]] or [[https://ipfs.io/][IPFS]] for hosting created websites.

=usability=
One of the major user feedbacks was the inconvenience of the two-step analysis of the data.
User would load the initial data, manipulate the settings and generate an internal representation in a form of a JSON file (see [[previous_tech_arch][Technical Architecture]]).
This file had to be than loaded into the program again to generate the visualization, when in fact this step simply created a directory with the files bundled together.
This was driven by the idea that users might want to combine different data-sets, by merging these JSON files together.

#+CAPTION: merging data in the previous version of SPREAD
file:current_system1.png

In practice this turned out to be of marginal importance for the users.
New system should simplify and streamline the process of obtaining a visualization, within a minimal number of steps needed.

=use of D3.js library=
Even today D3.js is still a great way for creating one-off visualizations on the web.
However it makes a poor fit with modern web application frameworks, directly overlapping with how these frameworks manipulate the browsers DOM.
It is also a fairly low-level library, providing mainly graph primitives and not offering any built-in capabilities for working with maps and geo-data.
The modfied system should utilize a library with an API directly aimed at working with maps to produce the visualizations.

** DONE Project Purpose

The magnitude of these changes deems it necessary to replace the existing system with a new one.
Large parts of the codebase, providing the parsing and analysis capabilities can be re-used, and wrapped as a web-server with API endpoints for interacting with the briwser client application [[goals_and_objectives][(see System Goals and Objectives]]).

** DONE System Goals and Objectives <<goals_and_objectives>>
# Briefly describe the goals and objectives of the new or modified system. Clearly state the business and/or operational problem that will be solved.

New system ought to provide a functional, user-friendly web-based tool that will serve as successor to the [[https://rega.kuleuven.be/cev/ecv/software/spread][SPREAD software]] to visualize Bayesian phylogeographic estimates.
The tool should be able to load both discrete and continuous phylogeographic estimates produced by BEAST and interactively visualize them as projections on geographic maps, based on the annotated and user-provided information.

It will replace the existing system and allevite all of the problems plaguing it, namely the data persistance problems, the usability issues and the problems with sharing of the produced visualisations.
It will provide ways for users to manage, store and revisit their data and visualisations

** DONE Proposed System
# Instructions: Provide a succinct description of the proposed system. Sections 5 and 6 will describe the proposed system in more detail.
*** DONE System Scope
Here we outline the responsibilities and boundaries of the proposed system.

=parsing of BEAST produced inputs=
This version of Spread should be capable of processing the following inputs:
- Summary tree files with discrete annotations
- Summary tree files with continuous annotations
- Files with distribution of trees with continuous trait annotations
- Log files containing a posterior distribution of rate indicators from a Bayesian stochastic search variable selection procedure.

=user management=
Another responsibility of the system is to maintains user sessions.
Specifically software will handle
- email based (i.e. magic links) login and sign-on on multiple devices
- session and management (cookie based)

=data persistance=
Data persistance for every user's account means storing:
- BEAST input files per analysis
- settings used to parse those files
- resulting visualisations, with the ability to share them (through URLs)

=visualisations=
The end-product of the software will be the map-based interactive visualisations.
They should maintain have the following features:
- interactive, with time based animation
- overlayed on maps
- zoom-in and zoom-out on the details
- interactive /detail-on-demand/: select and highlight taxa (based on string content) and locations
- ability to hide elements of visualisation: nodes, branches, polygons, map elements etc
- export to svg graphics

*** DONE Business Processes Supported

Below diagram is a high-level overview of the supported processes.

#+begin_src plantuml :file business_process.png
(*) --> if "user authenticated?" then
  -->[true] "show user home page" as authed
else
  -->[false] "send email with magic link"
  --> "open link"
  --> authed

authed --> "new analysis" as new
--> "import data"
--> "set parsing settings" as settings
--> "parse data and generate visualisation" as output

authed --> "edit previous analysis" as edit

edit --> "load new data"
--> settings

edit --> "edit parsing settings"
--> output
#+end_src
#+RESULTS:
[[file:business_process.png]]

They can generally be divided into a process of user login and authentication and the process of analysing and visualizing the data.

*** DONE High-Level Functional Requirements

General user-interface requirements:

- A minimal number of steps to obtain a good quality visualization
- Animated visualization of phylogenies projected on maps (with the ability to freeze and export)
- The ability to select and highlight taxa (based on string content) and locations
- Custom coloring and styling
- The ability to zoom in on parts of the projection
- Good export capabilities (vector-based graphics)
- Ensure browser compatibility with popular browsers
- The ability to retrieve and edit previous analyses
- Sharing of analyses through URLs
- User authentication and management

*** DONE Summary of Changes
# Instructions: If changing an existing system, briefly summarize the changes that this project will make to the system (e.g., functionality changes, technology changes, environment changes.

The majority of the changes will be focused on creating a client-server architecture.

The new system, although requires substantial changes that warrant a new code-base, will be able to re-use some parts of the previous releases.
Specifically the numerical methods and algorithms responsible for the parsing of the tree files as well as computing the various statistics can be used with the new application, providing it also uses JVM as it's runtime environment.

# Depending on the exact programming language chosen

User authentication and management, webserver endpoints for interacting with the application as well as Object and Relational storage will have to be developed.
The visualization engine, responsible for displaying the analyzed data will also be developed anew, with a different set of technologies.

The deployment environment will be changed from a desktop-based application to a server / client architecture.
The exact infrastructure will most probably be coming form a cloud provider, with instances of a Compute Cloud for hosting the server and the client server to the users browsers, RDS for Relational storage and S3 or similar solution used for the object storage.

* IN-PROGRESS Factors Influencing Technical Design
# Instructions: This section describes the standards, assumptions, and constraints that influence the technical design of the proposed system.
** +Relevant Standards+
** IN-PROGRESS Assumptions and Dependencies
# Instructions: Describe any assumptions or dependencies regarding the system and its use.

Due to the specialized nature of the system, we do not expect the application to be subject to a significant network traffic.
Nonetheless the size of the files and the associated meta-data used in the application can be quite significant, and the architecture needs to take into account that fact when uplaoding them in http requests.

The client part of the system, runing in the browser environment will most likely be viewed only on large screen sizes, which can influence the design.

** IN-PROGRESS Constraints

# Instructions: Describe any limitations or constraints that have a significant impact on the design of the system. Such constraints may be imposed by any of the following (the list is not exhaustive):
#     • Hardware or software environment
#     • End-user environment
#     • Availability of resources
#     • Interoperability requirements
#     • Interface/protocol requirements
#     • Data repository and distribution requirements
#     • Other requirements described in the Requirements Document

Chosing the server-client over a previous desktop based architecture lifts many of the constraints of the legacy system, previous mentioned in [[rationale][Goals, Objectives, and Rationale for New or Significantly Modified System]].
The client part of the application will consist of static content running in the end-users browser environment, therefore simply needs to meet a standard set of requirements for a browser-based application and be inter-operable with modern browsers.


# TODO : querying the JSON




** TODO Design Goals
* TODO Proposed System
* TODO High-Level Operational Requirements and Characteristics
*** TODO User Community Description
*** TODO Non-Functional Requirements
** TODO High-Level Architecture
*** TODO Application Architecture
*** TODO Information Architecture
*** TODO Interface Architecture
*** TODO Technology Architecture

[[https://reactjs.org/][React]] or [[https://reagent-project.github.io/][Reagent]]
[[https://docs.kepler.gl/docs/api-reference][Kepler]] or [[https://vega.github.io/vega-lite/examples/][Vega]]

*** TODO Security and Privacy Architecture
* TODO Analysis of the Proposed System
** TODO Impact Analysis
*** TODO Operational Impacts
*** TODO Organizational Impacts
** TODO Risks
** TODO Issues to Resolve
** TODO Critical Success Factors for Remainder of Project
* Appendix A: Glossary
- BEAST: software package for phylogenetic analysis with an emphasis on time-scaled trees.
- phylodynamics:
- phylogenetics
- Bayesian inference
- phylogenetic tree: directed, bifurcating graph depicting ancestral relationship.
- MCMC
